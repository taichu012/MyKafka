[INFO ] [2016-06-29 15:40:05] [MyKafkaDemo:main:51] Start zookeeper...wait 10s...!
[INFO ] [2016-06-29 15:40:15] [MyKafkaDemo:main:73] Start kafka...wait 30s...!
[INFO ] [2016-06-29 15:40:45] [AbstractConfig:logAll:178] ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [localhost:9092]
	client.id = 
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

[INFO ] [2016-06-29 15:40:45] [AbstractConfig:logAll:178] ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [localhost:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

[INFO ] [2016-06-29 15:40:45] [AppInfoParser$AppInfo:<init>:83] Kafka version : 0.10.0.0
[INFO ] [2016-06-29 15:40:45] [AppInfoParser$AppInfo:<init>:84] Kafka commitId : b8642491e78c5a13
[INFO ] [2016-06-29 15:40:45] [AbstractConfig:logAll:178] ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [localhost:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = testgroup1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

[INFO ] [2016-06-29 15:40:45] [AbstractConfig:logAll:178] ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [localhost:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = testgroup1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

[INFO ] [2016-06-29 15:40:45] [AppInfoParser$AppInfo:<init>:83] Kafka version : 0.10.0.0
[INFO ] [2016-06-29 15:40:45] [AppInfoParser$AppInfo:<init>:84] Kafka commitId : b8642491e78c5a13
[INFO ] [2016-06-29 15:40:45] [MyKafkaDemo:main:110] press ENTER to call System.exit() and run the shutdown routine.
[INFO ] [2016-06-29 15:40:45] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_1] is sent.
[INFO ] [2016-06-29 15:40:45] [AbstractCoordinator:handleGroupMetadataResponse:505] Discovered coordinator sh2-chenc01.vimicro.com:9092 (id: 2147483647 rack: null) for group testgroup1.
[INFO ] [2016-06-29 15:40:45] [ConsumerCoordinator:onJoinPrepare:280] Revoking previously assigned partitions [] for group testgroup1
[INFO ] [2016-06-29 15:40:45] [AbstractCoordinator:sendJoinGroupRequest:326] (Re-)joining group testgroup1
[INFO ] [2016-06-29 15:40:45] [AbstractCoordinator$SyncGroupResponseHandler:handle:434] Successfully joined group testgroup1 with generation 1
[INFO ] [2016-06-29 15:40:45] [ConsumerCoordinator:onJoinComplete:219] Setting newly assigned partitions [testtopic1-0, testtopic3-0, testtopic2-0] for group testgroup1
[INFO ] [2016-06-29 15:40:47] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_2] is sent.
[INFO ] [2016-06-29 15:40:49] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_3] is sent.
[INFO ] [2016-06-29 15:40:51] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_4] is sent.
[INFO ] [2016-06-29 15:40:53] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_5] is sent.
[INFO ] [2016-06-29 15:40:55] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_6] is sent.
[INFO ] [2016-06-29 15:40:57] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_7] is sent.
[INFO ] [2016-06-29 15:40:59] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_8] is sent.
[INFO ] [2016-06-29 15:41:01] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_9] is sent.
[INFO ] [2016-06-29 15:41:03] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_10] is sent.
[INFO ] [2016-06-29 15:41:05] [MyKafkaProducer:run:110] Producer: msg=[MessageTo_Broker_消息MSG_11] is sent.
[INFO ] [2016-06-29 15:41:06] [MyKafkaDemo:ExitHandle:124] MyKafkaDemo:准备执行退出前的操作！
[INFO ] [2016-06-29 15:41:06] [MyKafkaDemo:ExitHandle:128] MyKafkaDemo:Try to stop producer, wait 2s...
[INFO ] [2016-06-29 15:41:08] [MyKafkaDemo:ExitHandle:132] MyKafkaDemo:Try to stop consumer, wait 2s...
[INFO ] [2016-06-29 15:41:10] [MyKafkaDemo:ExitHandle:137] MyKafkaDemo:Try to stop kafka, wait 10s...
[INFO ] [2016-06-29 15:41:20] [MyKafkaDemo:ExitHandle:141] MyKafkaDemo:Try to stop zookeeper, wait 10s...
[INFO ] [2016-06-29 15:41:30] [MyKafkaDemo:ExitHandle:147] MyKafkaDemo:退出前的操作退出完成！
[INFO ] [2016-06-29 15:46:27] [MyKafkaDemo:main:51] Start zookeeper...wait 10s...!
[INFO ] [2016-06-29 15:46:37] [MyKafkaDemo:main:73] Start kafka...wait 30s...!
[INFO ] [2016-06-29 15:47:07] [AbstractConfig:logAll:178] ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [localhost:9092]
	client.id = 
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

[INFO ] [2016-06-29 15:47:08] [AbstractConfig:logAll:178] ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [localhost:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

[INFO ] [2016-06-29 15:47:08] [AppInfoParser$AppInfo:<init>:83] Kafka version : 0.10.0.0
[INFO ] [2016-06-29 15:47:08] [AppInfoParser$AppInfo:<init>:84] Kafka commitId : b8642491e78c5a13
[INFO ] [2016-06-29 15:47:08] [AbstractConfig:logAll:178] ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [localhost:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = testgroup1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

[INFO ] [2016-06-29 15:47:08] [AbstractConfig:logAll:178] ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [localhost:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = testgroup1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

[INFO ] [2016-06-29 15:47:08] [AppInfoParser$AppInfo:<init>:83] Kafka version : 0.10.0.0
[INFO ] [2016-06-29 15:47:08] [AppInfoParser$AppInfo:<init>:84] Kafka commitId : b8642491e78c5a13
[INFO ] [2016-06-29 15:47:08] [MyKafkaDemo:main:110] press ENTER to call System.exit() and run the shutdown routine.
[INFO ] [2016-06-29 15:47:08] [AbstractCoordinator:handleGroupMetadataResponse:505] Discovered coordinator sh2-chenc01.vimicro.com:9092 (id: 2147483647 rack: null) for group testgroup1.
[INFO ] [2016-06-29 15:47:08] [ConsumerCoordinator:onJoinPrepare:280] Revoking previously assigned partitions [] for group testgroup1
[INFO ] [2016-06-29 15:47:08] [AbstractCoordinator:sendJoinGroupRequest:326] (Re-)joining group testgroup1
[INFO ] [2016-06-29 15:47:08] [AbstractCoordinator$SyncGroupResponseHandler:handle:434] Successfully joined group testgroup1 with generation 1
[INFO ] [2016-06-29 15:47:08] [ConsumerCoordinator:onJoinComplete:219] Setting newly assigned partitions [testtopic1-0, testtopic3-0, testtopic2-0] for group testgroup1
[INFO ] [2016-06-29 15:47:39] [MyKafkaDemo:ExitHandle:124] MyKafkaDemo:准备执行退出前的操作！
[INFO ] [2016-06-29 15:47:39] [MyKafkaDemo:ExitHandle:128] MyKafkaDemo:Try to stop producer, wait 2s...
[INFO ] [2016-06-29 15:47:41] [MyKafkaDemo:ExitHandle:132] MyKafkaDemo:Try to stop consumer, wait 2s...
[INFO ] [2016-06-29 15:47:43] [MyKafkaDemo:ExitHandle:137] MyKafkaDemo:Try to stop kafka, wait 10s...
[INFO ] [2016-06-29 15:47:53] [MyKafkaDemo:ExitHandle:141] MyKafkaDemo:Try to stop zookeeper, wait 10s...
[INFO ] [2016-06-29 15:48:03] [MyKafkaDemo:ExitHandle:147] MyKafkaDemo:退出前的操作退出完成！
[INFO ] [2016-06-29 15:54:19] [MyKafkaDemo:main:51] Start zookeeper...wait 10s...!
[INFO ] [2016-06-29 15:54:29] [MyKafkaDemo:main:73] Start kafka...wait 30s...!
[INFO ] [2016-06-29 15:54:59] [AbstractConfig:logAll:178] ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [localhost:9092]
	client.id = 
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

[INFO ] [2016-06-29 15:54:59] [AbstractConfig:logAll:178] ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [localhost:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

[INFO ] [2016-06-29 15:54:59] [AppInfoParser$AppInfo:<init>:83] Kafka version : 0.10.0.0
[INFO ] [2016-06-29 15:54:59] [AppInfoParser$AppInfo:<init>:84] Kafka commitId : b8642491e78c5a13
[INFO ] [2016-06-29 15:54:59] [AbstractConfig:logAll:178] ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [localhost:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = testgroup1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

[INFO ] [2016-06-29 15:54:59] [AbstractConfig:logAll:178] ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [localhost:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = testgroup1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

[INFO ] [2016-06-29 15:54:59] [AppInfoParser$AppInfo:<init>:83] Kafka version : 0.10.0.0
[INFO ] [2016-06-29 15:54:59] [AppInfoParser$AppInfo:<init>:84] Kafka commitId : b8642491e78c5a13
[INFO ] [2016-06-29 15:54:59] [MyKafkaDemo:main:110] press ENTER to call System.exit() and run the shutdown routine.
[INFO ] [2016-06-29 15:56:18] [MyKafkaDemo:main:51] Start zookeeper...wait 10s...!
[INFO ] [2016-06-29 15:56:28] [MyKafkaDemo:main:73] Start kafka...wait 30s...!
[INFO ] [2016-06-29 15:56:58] [AbstractConfig:logAll:178] ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [localhost:9092]
	client.id = 
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

[INFO ] [2016-06-29 15:56:58] [AbstractConfig:logAll:178] ProducerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 30000
	ssl.truststore.password = null
	retry.backoff.ms = 100
	buffer.memory = 33554432
	batch.size = 16384
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 32768
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	max.in.flight.requests.per.connection = 5
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	bootstrap.servers = [localhost:9092]
	client.id = producer-1
	max.request.size = 1048576
	acks = all
	linger.ms = 1
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	metadata.fetch.timeout.ms = 60000
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
	ssl.truststore.location = null
	ssl.keystore.password = null
	block.on.buffer.full = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	timeout.ms = 30000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	metric.reporters = []
	ssl.truststore.type = JKS
	compression.type = none
	retries = 0
	max.block.ms = 60000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS

[INFO ] [2016-06-29 15:56:58] [AppInfoParser$AppInfo:<init>:83] Kafka version : 0.10.0.0
[INFO ] [2016-06-29 15:56:58] [AppInfoParser$AppInfo:<init>:84] Kafka commitId : b8642491e78c5a13
[INFO ] [2016-06-29 15:56:58] [AbstractConfig:logAll:178] ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [localhost:9092]
	client.id = 
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = testgroup1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

[INFO ] [2016-06-29 15:56:58] [AbstractConfig:logAll:178] ConsumerConfig values: 
	interceptor.classes = null
	request.timeout.ms = 40000
	check.crcs = true
	ssl.truststore.password = null
	retry.backoff.ms = 100
	ssl.keymanager.algorithm = SunX509
	receive.buffer.bytes = 65536
	ssl.key.password = null
	ssl.cipher.suites = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.service.name = null
	ssl.provider = null
	session.timeout.ms = 30000
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	max.poll.records = 2147483647
	bootstrap.servers = [localhost:9092]
	client.id = consumer-1
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	auto.offset.reset = latest
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	max.partition.fetch.bytes = 1048576
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	ssl.endpoint.identification.algorithm = null
	ssl.keystore.location = null
	ssl.truststore.location = null
	exclude.internal.topics = true
	ssl.keystore.password = null
	metrics.sample.window.ms = 30000
	security.protocol = PLAINTEXT
	metadata.max.age.ms = 300000
	auto.commit.interval.ms = 1000
	ssl.protocol = TLS
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	ssl.trustmanager.algorithm = PKIX
	group.id = testgroup1
	enable.auto.commit = true
	metric.reporters = []
	ssl.truststore.type = JKS
	send.buffer.bytes = 131072
	reconnect.backoff.ms = 50
	metrics.num.samples = 2
	ssl.keystore.type = JKS
	heartbeat.interval.ms = 3000

[INFO ] [2016-06-29 15:56:58] [AppInfoParser$AppInfo:<init>:83] Kafka version : 0.10.0.0
[INFO ] [2016-06-29 15:56:58] [AppInfoParser$AppInfo:<init>:84] Kafka commitId : b8642491e78c5a13
[INFO ] [2016-06-29 15:56:58] [MyKafkaDemo:main:110] press ENTER to call System.exit() and run the shutdown routine.
[INFO ] [2016-06-29 15:56:58] [AbstractCoordinator:handleGroupMetadataResponse:505] Discovered coordinator sh2-chenc01.vimicro.com:9092 (id: 2147483647 rack: null) for group testgroup1.
[INFO ] [2016-06-29 15:56:58] [ConsumerCoordinator:onJoinPrepare:280] Revoking previously assigned partitions [] for group testgroup1
[INFO ] [2016-06-29 15:56:58] [AbstractCoordinator:sendJoinGroupRequest:326] (Re-)joining group testgroup1
[INFO ] [2016-06-29 15:56:59] [AbstractCoordinator$SyncGroupResponseHandler:handle:434] Successfully joined group testgroup1 with generation 1
[INFO ] [2016-06-29 15:56:59] [ConsumerCoordinator:onJoinComplete:219] Setting newly assigned partitions [testtopic1-0, testtopic3-0, testtopic2-0] for group testgroup1
[INFO ] [2016-06-29 15:57:48] [MyKafkaDemo:ExitHandle:124] MyKafkaDemo:准备执行退出前的操作！
[INFO ] [2016-06-29 15:57:48] [MyKafkaDemo:ExitHandle:128] MyKafkaDemo:Try to stop producer, wait 2s...
[INFO ] [2016-06-29 15:57:50] [MyKafkaDemo:ExitHandle:132] MyKafkaDemo:Try to stop consumer, wait 2s...
[INFO ] [2016-06-29 15:57:52] [MyKafkaDemo:ExitHandle:137] MyKafkaDemo:Try to stop kafka, wait 10s...
[INFO ] [2016-06-29 15:58:02] [MyKafkaDemo:ExitHandle:141] MyKafkaDemo:Try to stop zookeeper, wait 10s...
[INFO ] [2016-06-29 15:58:12] [MyKafkaDemo:ExitHandle:147] MyKafkaDemo:退出前的操作退出完成！
